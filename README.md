# ğŸ“ˆ Moroccan Telecom Churn Prediction Dashboard

Bienvenue dans ce projet de **dÃ©tection du churn client** basÃ© sur un jeu de donnÃ©es synthÃ©tique reprÃ©sentant les abonnÃ©s d'un opÃ©rateur tÃ©lÃ©com au Maroc. Il s'agit d'une **application interactive dÃ©veloppÃ©e avec Streamlit**, intÃ©grant des modÃ¨les de machine learning optimisÃ©s, une interface visuelle soignÃ©e et des outils d'analyse avancÃ©e.

---

## ğŸ¯ Objectifs

- DÃ©tecter les clients Ã  risque de rÃ©siliation (churn) avec haute prÃ©cision
- Proposer des recommandations ciblÃ©es pour la fidÃ©lisation
- Permettre une visualisation dynamique et personnalisÃ©e des donnÃ©es
- Valoriser les compÃ©tences en **Big Data Analytics**, **ML Explainability** et **Hyperparameter Optimization**

---

## âœ¨ CaractÃ©ristiques principales

- **1M donnÃ©es synthÃ©tiques** avec modÃ©lisation probabiliste rÃ©aliste du churn
- **60+ features engineered** (interactions, ratios, indicateurs de risque, loyalty score)
- **ModÃ¨les optimisÃ©s** avec hyperparameter tuning BayÃ©sien (Optuna)
- **Seuil de dÃ©cision optimisÃ©** (0.300) pour maximiser le profit business
- **ROC-AUC: 0.726** avec 62% de recall sur les churners
- **Interface interactive** avec dashboard Streamlit
- **ExplicabilitÃ©** avec analyse SHAP et feature importance

---

## ğŸ§° Technologies utilisÃ©es

- **Python 3.10+**
- **Streamlit** (application web interactive)
- **LightGBM & XGBoost** (modÃ¨les de classification optimisÃ©s)
- **Optuna** (optimisation bayÃ©sienne des hyperparamÃ¨tres)
- **Scikit-learn** (prÃ©traitement, mÃ©triques, validation)
- **SHAP** (explicabilitÃ© des prÃ©dictions)
- **Plotly & Matplotlib** (visualisations interactives)
- **Joblib** (sÃ©rialisation des modÃ¨les)
- **Pandas / NumPy** (traitement de donnÃ©es)

---

## ğŸš€ Installation et lancement

### PrÃ©requis
- Python 3.10 ou supÃ©rieur
- pip (gestionnaire de paquets Python)

### Ã‰tapes d'installation

1. **Cloner le repository**
```bash
git clone https://github.com/elmehdi03/churn_prediction_dashboard.git
cd churn_prediction_dashboard
```

2. **CrÃ©er un environnement virtuel (recommandÃ©)**
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

4. **Lancer l'application**
```bash
streamlit run streamlitApp.py
```

L'application s'ouvrira automatiquement dans votre navigateur Ã  l'adresse `http://localhost:8501`

---

## ğŸ“ Structure du projet
```
churn_prediction_dashboard/
â”œâ”€â”€ data/                                    # DonnÃ©es
â”‚   â”œâ”€â”€ synthetic_moroccan_churn_1M.csv     # Dataset RAW (1M lignes, 11 colonnes)
â”‚   â””â”€â”€ README.md                            # Documentation des donnÃ©es
â”œâ”€â”€ models/                                  # ModÃ¨les entraÃ®nÃ©s et artefacts
â”‚   â”œâ”€â”€ model_lightgbm_churn.joblib         # ModÃ¨le LightGBM (baseline)
â”‚   â”œâ”€â”€ model_lightgbm_tuned_churn.joblib   # ModÃ¨le LightGBM optimisÃ©
â”‚   â”œâ”€â”€ model_xgboost_churn.joblib          # ModÃ¨le XGBoost
â”‚   â”œâ”€â”€ model_best_churn.joblib             # Meilleur modÃ¨le
â”‚   â”œâ”€â”€ best_hyperparameters.joblib         # HyperparamÃ¨tres optimaux
â”‚   â”œâ”€â”€ encoder.joblib                       # OneHotEncoder
â”‚   â”œâ”€â”€ scaler_churn.joblib                 # StandardScaler
â”‚   â”œâ”€â”€ features.joblib                      # Noms des features (60)
â”‚   â”œâ”€â”€ categorical_columns.joblib           # Colonnes catÃ©gorielles
â”‚   â”œâ”€â”€ numerical_columns.joblib             # Colonnes numÃ©riques
â”‚   â”œâ”€â”€ binary_columns.joblib                # Colonnes binaires
â”‚   â”œâ”€â”€ scaler_features.joblib              # Features Ã  standardiser
â”‚   â”œâ”€â”€ optimal_threshold.joblib            # Seuil optimal (0.300)
â”‚   â””â”€â”€ README.md                            # Documentation des modÃ¨les
â”œâ”€â”€ streamlitApp.py                          # Application Streamlit principale
â”œâ”€â”€ NoteBook.ipynb                           # Pipeline ML complet (24 cellules)
â”‚                                            # - Data generation (realistic churn)
â”‚                                            # - Feature engineering (21 features)
â”‚                                            # - Preprocessing & encoding
â”‚                                            # - Model training & evaluation
â”‚                                            # - Hyperparameter tuning (Optuna)
â”‚                                            # - Threshold optimization (business value)
â”œâ”€â”€ requirements.txt                         # DÃ©pendances Python
â”œâ”€â”€ .gitignore                               # Fichiers Ã  ignorer par Git
â”œâ”€â”€ LICENSE                                  # Licence du projet (MIT)
â””â”€â”€ README.md                                # Documentation (ce fichier)
```

---

## ğŸ”¬ Pipeline Machine Learning

Le notebook `NoteBook.ipynb` contient le pipeline complet :

### 1. **GÃ©nÃ©ration de donnÃ©es synthÃ©tiques**
   - 1M clients avec 10 features de base
   - ModÃ©lisation probabiliste du churn (9 facteurs pondÃ©rÃ©s)
   - Taux de churn rÃ©aliste : 60.46%
   - **Format RAW**: 11 colonnes (7 catÃ©gorielles, 3 numÃ©riques, 1 target)

### 2. **Feature Engineering (automatique)**
   - Le Streamlit app crÃ©e automatiquement toutes les features:
   - 4 features d'interaction (ex: `is_young_prepaid`)
   - 2 features de ratio (ex: `tenure_income_ratio`)
   - 3 features catÃ©gorielles binÃ©es (age_group, revenue_tier, tenure_category)
   - 7 indicateurs de risque binaires
   - 1 score de fidÃ©litÃ© composite
   - 3 features statistiques (z-score, percentiles)
   - **Total: 31 features crÃ©Ã©es â†’ 60 features aprÃ¨s encoding**

### 3. **PrÃ©traitement**
   - One-Hot Encoding (10 colonnes catÃ©gorielles â†’ 40 features)
   - Standardisation des features numÃ©riques uniquement
   - Pas de PCA (prÃ©serve l'interprÃ©tabilitÃ©)

### 4. **EntraÃ®nement & Ã‰valuation**
   - Train/Test split: 800k/200k (stratifiÃ©)
   - ModÃ¨les: XGBoost & LightGBM
   - Cross-validation 5-fold
   - MÃ©triques: ROC-AUC, Precision, Recall, F1-Score

### 5. **Optimisation des hyperparamÃ¨tres**
   - Framework: Optuna (Bayesian optimization)
   - 50 trials avec TPE sampler
   - Optimisation sur 200k Ã©chantillon (3-fold CV)
   - Temps: ~3.5 minutes
   - **AmÃ©lioration: +0.06% ROC-AUC**

### 6. **Optimisation du seuil de dÃ©cision**
   - Tests de 50 seuils (0.30 - 0.80)
   - Analyse coÃ»ts business:
     - Faux NÃ©gatif (churner manquÃ©): $100
     - Faux Positif (campagne inutile): $10
     - Vrai Positif (client sauvÃ©): -$20 (gain net)
   - **Seuil optimal: 0.300** (maximise le profit)
   - AmÃ©liore le recall tout en minimisant les coÃ»ts

### 7. **RÃ©sultats finaux**
   - **LightGBM optimisÃ© (seuil 0.300):**
     - ROC-AUC: **0.7263**
     - Accuracy: **65.38%**
     - Precision: **76%**
     - Recall: **62%** (dÃ©tecte 62% des churners)
     - F1-Score: **0.68**
     - **Seuil de dÃ©cision: 0.300** (optimisÃ© pour profit)

---

## ğŸ“Š Comparaison des performances

| MÃ©trique | Avant optimisation | AprÃ¨s Optuna | AmÃ©lioration |
|----------|-------------------|--------------|-------------|
| ROC-AUC | 0.7257 | 0.7263 | +0.06% |
| Accuracy | 65.00% | 65.38% | +0.38% |
| Recall | 61% | 62% | +1% |
| F1-Score | 0.68 | 0.68 | Stable |

**Impact business:** Sur 120,925 churners dans le test set, le modÃ¨le optimisÃ© en dÃ©tecte **~75,000**, soit environ 600 clients supplÃ©mentaires par rapport au modÃ¨le de base.

---

## ğŸ‘¤ Auteur

DÃ©veloppÃ© par **El Mehdi El Youbi Rmich**  
ğŸ“ Maroc | ğŸ“§ mehdi.eloubi@gmail.com  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/el-mehdi-el-youbi-rmich-574941249/)  
